{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.kube.pod import get_pod_names\n",
    "from src.prometheus.time_utils import generate_time\n",
    "from src.prometheus.metrics import metric_labels\n",
    "from src.prometheus.constants import prometheus_endpoint, prometheus_query, excluding_services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 420\n",
    "offsets = [1598047832.6821344, 1598048432.9423163, 1598049032.9943507, 1598049633.0863874, 1598050233.1645138, 1598050833.2558558, 1598051433.366836, 1598052033.4203055, 1598052633.4842124, 1598053233.699553, 1598053833.741907, 1598054433.789637, 1598055033.8514934, 1598055634.24382, 1598056234.3267875, 1598056834.3907578, 1598057434.4455614, 1598058034.5075765, 1598058634.5720835, 1598059234.6254506, 1598059834.6723816, 1598060434.7206242, 1598061034.7685883, 1598061634.8055122, 1598062234.841223, 1598062834.9602003, 1598063435.252741, 1598064035.3158479, 1598064635.5269578, 1598065235.6270418, 1598065835.667722, 1598066435.7218814, 1598067035.7902415, 1598067635.8587837, 1598068236.2302053, 1598068836.2907255, 1598069436.3609302, 1598070036.4161923, 1598070636.4580853, 1598071236.493694, 1598071836.6565282, 1598072436.7347512] \n",
    "offsets_in_ms = [(((int(offset) - data_length + 1)), int(offset)) for offset in offsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods = ['vehicles-service', 'identity-service', 'customers-service', 'deliveries-service', 'orders-service',\n",
    "        'availability-service', 'parcels-service', 'pricing-service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for offset in offsets_in_ms:\n",
    "    prom_data_by_pods = {}\n",
    "    for job_name in metric_labels:\n",
    "        for metric in metric_labels[job_name]:\n",
    "            response =requests.get(prometheus_endpoint + prometheus_query,\n",
    "                                   params={'query': metric[1], 'start': offset[0], 'end': offset[1], 'step':1})\n",
    "            prometheus_data = response.json()['data']['result']\n",
    "\n",
    "            for pod in pods:\n",
    "                metric_data = next(data['values'] for data in prometheus_data if data['metric']['app'] == pod)\n",
    "                metric_data = map(lambda val: float(val[1]), metric_data)\n",
    "                prom_data_by_pods[metric[0] + '_' + pod] = metric_data\n",
    "    datasets.append(pd.DataFrame.from_dict(prom_data_by_pods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, d_t in enumerate(datasets):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(d_t)\n",
    "    datasets[idx] = pd.DataFrame(x_scaled, columns=d_t.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_by_service = 9\n",
    "prediction_column_idx_in_batch = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_service_index = pods.index('vehicles-service')\n",
    "vehicle_service_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17640, 72)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat(datasets)\n",
    "dataset.shape\n",
    "\n",
    "# 42 batches. Each 420 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17640, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_dataset = dataset.iloc[:, [(len(pods) * x) + vehicle_service_index for x in range(0, features_by_service)]]\n",
    "vehicle_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 420\n",
    "batches = [(x * batch_size, (x + 1) * batch_size) for x in range(0, int(dataset.shape[0]/420))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset =[tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(vehicle_dataset.iloc[batch[0]:batch[1]].values, tf.float32)\n",
    "        )\n",
    "    ) for batch in batches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 60\n",
    "shift = 10\n",
    "\n",
    "x_size = int((batch_size - window_size) / shift) + 1\n",
    "skip_y = int(window_size/shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_x = []\n",
    "datasets_y = []\n",
    "for idx, dataset in enumerate(tf_dataset):\n",
    "    tf_dataset[idx] = tf_dataset[idx].window(window_size, shift, 1, True)\n",
    "    tf_dataset[idx] = tf_dataset[idx].flat_map(lambda d: d.batch(window_size))\n",
    "    datasets_x.append(tf_dataset[idx].take(x_size - skip_y).map(lambda t: t[:, :-1])) # map to skip prediction column\n",
    "    datasets_y.append(tf_dataset[idx].skip(skip_y).map(lambda t: t[:shift, -1])) # map to take only prediction column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_batches(datasets):\n",
    "    datasets_as_tuple = tuple(datasets)\n",
    "    zipped = tf.data.Dataset.zip(datasets_as_tuple)\n",
    "    \n",
    "    return zipped.map(lambda *t: tf.stack(t, axis=0)) # merge batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_test_split(X, y, split = 0.7):\n",
    "    all_indexes = range(0, len(X))\n",
    "    indexes_train = random.sample(all_indexes, int(0.7 * len(X)))\n",
    "    indexes_test = list(set(all_indexes) - set(indexes_train))\n",
    "    \n",
    "    X_train_all = [X[i] for i in indexes_train]\n",
    "    y_train_all = [y[i] for i in indexes_train]\n",
    "\n",
    "    X_test_all = [X[i] for i in indexes_test]\n",
    "    y_test_all = [y[i] for i in indexes_test]\n",
    "    \n",
    "    return merge_batches(X_train_all), merge_batches(y_train_all), merge_batches(X_test_all), merge_batches(y_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(datasets_x, datasets_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (29, None, 8), types: tf.float32>\n",
      "<MapDataset shapes: (29, None), types: tf.float32>\n",
      "<MapDataset shapes: (13, None, 8), types: tf.float32>\n",
      "<MapDataset shapes: (13, None), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (42, None), types: tf.float32>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # 42 batches with windowed prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x in datasets_y:\n",
    "    for k in x:\n",
    "        print(k)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TestTensorflow] *",
   "language": "python",
   "name": "conda-env-TestTensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
